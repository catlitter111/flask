#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOv8å§¿æ€æ£€æµ‹æ¨¡å— - ROS2é€‚é…ç‰ˆæœ¬
================================
ç§»æ¤è‡ªyolov8_pose.pyï¼Œé€‚é…ROS2 Humbleç¯å¢ƒ
æä¾›äººä½“å§¿æ€æ£€æµ‹åŠŸèƒ½ï¼Œæ”¯æŒå…³é”®ç‚¹æ£€æµ‹å’Œéª¨æ¶ç»˜åˆ¶

ä½œè€…: AI Assistant
ç§»æ¤ç‰ˆæœ¬: v1.0.0
"""

import os
import sys
import time
import numpy as np
import cv2
import logging
from typing import List, Tuple, Optional, Union
from dataclasses import dataclass

# å¯¼å…¥RKNN Lite
try:
    from rknnlite.api import RKNNLite
    RKNN_AVAILABLE = True
except ImportError:
    RKNN_AVAILABLE = False
    print("âš ï¸ RKNN Liteæœªå®‰è£…ï¼Œå§¿æ€æ£€æµ‹åŠŸèƒ½ä¸å¯ç”¨")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€é…ç½®
CLASSES = ['person']
NMS_THRESH = 0.4
OBJECT_THRESH = 0.5

# å§¿æ€é¢œè‰²é…ç½®
POSE_PALETTE = np.array([
    [255, 128, 0], [255, 153, 51], [255, 178, 102], [230, 230, 0], [255, 153, 255],
    [153, 204, 255], [255, 102, 255], [255, 51, 255], [102, 178, 255], [51, 153, 255],
    [255, 153, 153], [255, 102, 102], [255, 51, 51], [153, 255, 153], [102, 255, 102],
    [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0], [255, 255, 255]
], dtype=np.uint8)

KPT_COLOR = POSE_PALETTE[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]

SKELETON = [
    [16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13], [6, 7], [6, 8], 
    [7, 9], [8, 10], [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]
]

LIMB_COLOR = POSE_PALETTE[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]


@dataclass
class PoseResult:
    """å§¿æ€æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    bbox: Tuple[int, int, int, int]  # (xmin, ymin, xmax, ymax)
    score: float
    keypoints: np.ndarray  # shape: (17, 3) - [x, y, confidence]
    class_id: int = 0


class YOLOv8PoseDetector:
    """YOLOv8å§¿æ€æ£€æµ‹å™¨"""
    
    def __init__(self, model_path: Optional[str] = None):
        """åˆå§‹åŒ–å§¿æ€æ£€æµ‹å™¨"""
        self.rknn = None
        self.model_loaded = False
        self.model_path = model_path
        
        if not RKNN_AVAILABLE:
            logger.error("RKNN Liteä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–å§¿æ€æ£€æµ‹å™¨")
            return
        
        # è‡ªåŠ¨æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        if self.model_path is None:
            self.model_path = self._find_model_file()
        
        if self.model_path and os.path.exists(self.model_path):
            self._load_model()
        else:
            logger.error(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {self.model_path}")
    
    def _find_model_file(self) -> Optional[str]:
        """æŸ¥æ‰¾YOLOv8å§¿æ€æ£€æµ‹æ¨¡å‹æ–‡ä»¶"""
        possible_paths = [
            # ROS2å®‰è£…è·¯å¾„
            os.path.join(os.path.dirname(__file__), '..', '..', '..', 'install', 'following_robot', 'share', 'following_robot', 'data', 'yolov8_pose.rknn'),
            # å¼€å‘ç¯å¢ƒè·¯å¾„
            os.path.join(os.path.dirname(__file__), '..', 'data', 'yolov8_pose.rknn'),
            # ç»å¯¹è·¯å¾„
            '/userdata/try_again/SelfFollowingROS2/src/following_robot/data/yolov8_pose.rknn',
        ]
        
        for path in possible_paths:
            abs_path = os.path.abspath(path)
            logger.info(f"æ£€æŸ¥æ¨¡å‹è·¯å¾„: {abs_path}")
            if os.path.exists(abs_path):
                logger.info(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {abs_path}")
                return abs_path
        
        logger.error("æœªæ‰¾åˆ°YOLOv8å§¿æ€æ£€æµ‹æ¨¡å‹æ–‡ä»¶")
        return None
    
    def _load_model(self):
        """åŠ è½½RKNNæ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½YOLOv8å§¿æ€æ£€æµ‹æ¨¡å‹: {self.model_path}")
            
            self.rknn = RKNNLite(verbose=False)
            
            # åŠ è½½æ¨¡å‹
            ret = self.rknn.load_rknn(self.model_path)
            if ret != 0:
                logger.error(f"åŠ è½½RKNNæ¨¡å‹å¤±è´¥: {self.model_path}")
                return
            
            # åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ
            logger.info("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒ...")
            ret = self.rknn.init_runtime()
            if ret != 0:
                logger.error("åˆå§‹åŒ–è¿è¡Œæ—¶ç¯å¢ƒå¤±è´¥")
                return
            
            self.model_loaded = True
            logger.info("âœ… YOLOv8å§¿æ€æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¼‚å¸¸: {e}")
            self.model_loaded = False
    
    def letterbox_resize(self, image: np.ndarray, size: Tuple[int, int], bg_color: int = 56) -> Tuple[np.ndarray, float, int, int]:
        """æŒ‰æ¯”ä¾‹ç¼©æ”¾å›¾åƒå¹¶å¡«å……"""
        target_width, target_height = size
        image_height, image_width, _ = image.shape
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        aspect_ratio = min(target_width / image_width, target_height / image_height)
        new_width = int(image_width * aspect_ratio)
        new_height = int(image_height * aspect_ratio)
        
        # æŒ‰æ¯”ä¾‹ç¼©æ”¾
        image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
        
        # åˆ›å»ºç”»å¸ƒå¹¶å¡«å……
        result_image = np.ones((target_height, target_width, 3), dtype=np.uint8) * bg_color
        offset_x = (target_width - new_width) // 2
        offset_y = (target_height - new_height) // 2
        result_image[offset_y:offset_y + new_height, offset_x:offset_x + new_width] = image
        
        return result_image, aspect_ratio, offset_x, offset_y
    
    def sigmoid(self, x: np.ndarray) -> np.ndarray:
        """Sigmoidæ¿€æ´»å‡½æ•°"""
        return 1 / (1 + np.exp(-np.clip(x, -250, 250)))
    
    def softmax(self, x: np.ndarray, axis: int = -1) -> np.ndarray:
        """Softmaxå‡½æ•°"""
        exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
        return exp_x / np.sum(exp_x, axis=axis, keepdims=True)
    
    def detect_pose(self, image: np.ndarray) -> List[PoseResult]:
        """æ£€æµ‹äººä½“å§¿æ€"""
        if not self.model_loaded or self.rknn is None:
            logger.warning("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œå§¿æ€æ£€æµ‹")
            return []
        
        try:
            # å›¾åƒé¢„å¤„ç†
            letterbox_img, aspect_ratio, offset_x, offset_y = self.letterbox_resize(image, (640, 640), 56)
            infer_img = letterbox_img[..., ::-1]  # BGR2RGB
            infer_img = np.expand_dims(infer_img, axis=0)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            
            # æ¨¡å‹æ¨ç†
            results = self.rknn.inference(inputs=[infer_img])
            
            if results is None or len(results) < 4:
                logger.warning("æ¨¡å‹æ¨ç†ç»“æœå¼‚å¸¸")
                return []
            
            # å¤„ç†è¾“å‡º
            all_detections = []
            keypoints_data = results[3]
            
            for i, output in enumerate(results[:3]):
                if output is None:
                    continue
                    
                # ç¡®å®šstrideå’Œindex
                if output.shape[2] == 20:
                    stride = 32
                    index = 20 * 4 * 20 * 4 + 20 * 2 * 20 * 2
                elif output.shape[2] == 40:
                    stride = 16
                    index = 20 * 4 * 20 * 4
                elif output.shape[2] == 80:
                    stride = 8
                    index = 0
                else:
                    continue
                
                feature = output.reshape(1, 65, -1)
                detections = self._process_output(feature, keypoints_data, index, 
                                               output.shape[3], output.shape[2], stride)
                all_detections.extend(detections)
            
            # NMS
            final_detections = self._nms(all_detections)
            
            # è½¬æ¢ä¸ºPoseResultæ ¼å¼
            pose_results = []
            for det in final_detections:
                # åæ ‡è½¬æ¢å›åŸå›¾
                xmin = int((det['xmin'] - offset_x) / aspect_ratio)
                ymin = int((det['ymin'] - offset_y) / aspect_ratio)
                xmax = int((det['xmax'] - offset_x) / aspect_ratio)
                ymax = int((det['ymax'] - offset_y) / aspect_ratio)
                
                # å…³é”®ç‚¹åæ ‡è½¬æ¢
                keypoints_converted = det['keypoint'].reshape(-1, 3).copy()
                keypoints_converted[:, 0] = (keypoints_converted[:, 0] - offset_x) / aspect_ratio
                keypoints_converted[:, 1] = (keypoints_converted[:, 1] - offset_y) / aspect_ratio
                
                pose_result = PoseResult(
                    bbox=(xmin, ymin, xmax, ymax),
                    score=det['score'],
                    keypoints=keypoints_converted,
                    class_id=det['class_id']
                )
                pose_results.append(pose_result)
            
            return pose_results
            
        except Exception as e:
            logger.error(f"å§¿æ€æ£€æµ‹å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _process_output(self, output: np.ndarray, keypoints: np.ndarray, index: int, 
                      model_w: int, model_h: int, stride: int) -> List[dict]:
        """å¤„ç†æ¨¡å‹è¾“å‡º"""
        detections = []
        
        xywh = output[:, :64, :]
        conf = self.sigmoid(output[:, 64:, :])
        
        for h in range(model_h):
            for w in range(model_w):
                for c in range(len(CLASSES)):
                    confidence = conf[0, c, (h * model_w) + w]
                    if confidence > OBJECT_THRESH:
                        # å¤„ç†è¾¹ç•Œæ¡†
                        xywh_ = xywh[0, :, (h * model_w) + w].reshape(1, 4, 16, 1)
                        data = np.array([i for i in range(16)]).reshape(1, 1, 16, 1)
                        xywh_ = self.softmax(xywh_, 2)
                        xywh_ = np.multiply(data, xywh_)
                        xywh_ = np.sum(xywh_, axis=2, keepdims=True).reshape(-1)
                        
                        # è½¬æ¢åæ ‡
                        xywh_temp = xywh_.copy()
                        xywh_temp[0] = (w + 0.5) - xywh_[0]
                        xywh_temp[1] = (h + 0.5) - xywh_[1]
                        xywh_temp[2] = (w + 0.5) + xywh_[2]
                        xywh_temp[3] = (h + 0.5) + xywh_[3]
                        
                        xywh_[0] = ((xywh_temp[0] + xywh_temp[2]) / 2)
                        xywh_[1] = ((xywh_temp[1] + xywh_temp[3]) / 2)
                        xywh_[2] = (xywh_temp[2] - xywh_temp[0])
                        xywh_[3] = (xywh_temp[3] - xywh_temp[1])
                        xywh_ = xywh_ * stride
                        
                        xmin = xywh_[0] - xywh_[2] / 2
                        ymin = xywh_[1] - xywh_[3] / 2
                        xmax = xywh_[0] + xywh_[2] / 2
                        ymax = xywh_[1] + xywh_[3] / 2
                        
                        # æå–å…³é”®ç‚¹
                        keypoint = keypoints[..., (h * model_w) + w + index]
                        keypoint[..., 0:2] = keypoint[..., 0:2] // 1
                        
                        detection = {
                            'class_id': c,
                            'score': confidence,
                            'xmin': xmin,
                            'ymin': ymin,
                            'xmax': xmax,
                            'ymax': ymax,
                            'keypoint': keypoint
                        }
                        detections.append(detection)
        
        return detections
    
    def _iou(self, box1: dict, box2: dict) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ¡†çš„IoU"""
        xmin = max(box1['xmin'], box2['xmin'])
        ymin = max(box1['ymin'], box2['ymin'])
        xmax = min(box1['xmax'], box2['xmax'])
        ymax = min(box1['ymax'], box2['ymax'])
        
        inner_width = max(0, xmax - xmin)
        inner_height = max(0, ymax - ymin)
        inner_area = inner_width * inner_height
        
        area1 = (box1['xmax'] - box1['xmin']) * (box1['ymax'] - box1['ymin'])
        area2 = (box2['xmax'] - box2['xmin']) * (box2['ymax'] - box2['ymin'])
        
        total = area1 + area2 - inner_area
        
        return inner_area / total if total > 0 else 0
    
    def _nms(self, detections: List[dict]) -> List[dict]:
        """éæå¤§å€¼æŠ‘åˆ¶"""
        if not detections:
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        sorted_detections = sorted(detections, key=lambda x: x['score'], reverse=True)
        result = []
        
        for i, det in enumerate(sorted_detections):
            if det['class_id'] == -1:  # å·²è¢«æŠ‘åˆ¶
                continue
                
            result.append(det)
            
            # æŠ‘åˆ¶é‡å çš„æ£€æµ‹æ¡†
            for j in range(i + 1, len(sorted_detections)):
                if sorted_detections[j]['class_id'] == det['class_id']:
                    iou_val = self._iou(det, sorted_detections[j])
                    if iou_val > NMS_THRESH:
                        sorted_detections[j]['class_id'] = -1
        
        return result
    
    def draw_pose(self, image: np.ndarray, pose_results: List[PoseResult]) -> np.ndarray:
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶å§¿æ€æ£€æµ‹ç»“æœ"""
        result_image = image.copy()
        
        for i, pose in enumerate(pose_results):
            xmin, ymin, xmax, ymax = pose.bbox
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(result_image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"Person {i+1}: {pose.score:.2f}"
            cv2.putText(result_image, label, (xmin, ymin - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶å…³é”®ç‚¹
            keypoints = pose.keypoints
            for k, (x, y, conf) in enumerate(keypoints):
                if x > 0 and y > 0 and conf > 0.5:  # åªç»˜åˆ¶ç½®ä¿¡åº¦é«˜çš„å…³é”®ç‚¹
                    color = [int(c) for c in KPT_COLOR[k]]
                    cv2.circle(result_image, (int(x), int(y)), 5, color, -1, lineType=cv2.LINE_AA)
            
            # ç»˜åˆ¶éª¨æ¶
            for k, (start_idx, end_idx) in enumerate(SKELETON):
                start_point = keypoints[start_idx - 1]  # ç´¢å¼•ä»1å¼€å§‹
                end_point = keypoints[end_idx - 1]
                
                if (start_point[0] > 0 and start_point[1] > 0 and start_point[2] > 0.5 and
                    end_point[0] > 0 and end_point[1] > 0 and end_point[2] > 0.5):
                    
                    color = [int(c) for c in LIMB_COLOR[k]]
                    cv2.line(result_image, 
                            (int(start_point[0]), int(start_point[1])),
                            (int(end_point[0]), int(end_point[1])),
                            color, thickness=2, lineType=cv2.LINE_AA)
        
        return result_image


# å…¨å±€æ£€æµ‹å™¨å®ä¾‹
_global_pose_detector = None

def get_pose_detector() -> YOLOv8PoseDetector:
    """è·å–å…¨å±€å§¿æ€æ£€æµ‹å™¨å®ä¾‹"""
    global _global_pose_detector
    if _global_pose_detector is None:
        _global_pose_detector = YOLOv8PoseDetector()
    return _global_pose_detector

def detect_human_pose(image: np.ndarray) -> List[PoseResult]:
    """æ£€æµ‹äººä½“å§¿æ€ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    detector = get_pose_detector()
    return detector.detect_pose(image)

def draw_human_pose(image: np.ndarray, pose_results: List[PoseResult]) -> np.ndarray:
    """ç»˜åˆ¶äººä½“å§¿æ€ï¼ˆä¾¿æ·å‡½æ•°ï¼‰"""
    detector = get_pose_detector()
    return detector.draw_pose(image, pose_results)


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•YOLOv8å§¿æ€æ£€æµ‹æ¨¡å—...")
    
    detector = YOLOv8PoseDetector()
    if detector.model_loaded:
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = np.zeros((480, 640, 3), dtype=np.uint8)
        cv2.rectangle(test_image, (200, 100), (400, 400), (255, 255, 255), -1)
        
        # è¿›è¡Œæ£€æµ‹
        results = detector.detect_pose(test_image)
        print(f"æ£€æµ‹åˆ° {len(results)} ä¸ªäººä½“å§¿æ€")
        
        if results:
            # ç»˜åˆ¶ç»“æœ
            result_image = detector.draw_pose(test_image, results)
            cv2.imwrite("/tmp/pose_detection_test.jpg", result_image)
            print("æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° /tmp/pose_detection_test.jpg")
    else:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥") 