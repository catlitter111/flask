#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾æå–èŠ‚ç‚¹æµ‹è¯•è„šæœ¬
==================
æµ‹è¯•ç‰¹å¾æå–æœåŠ¡çš„åŠŸèƒ½
"""

import rclpy
from rclpy.node import Node
from custom_msgs.srv import FeatureExtraction
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import numpy as np
import sys
import os


class FeatureExtractionTester(Node):
    """ç‰¹å¾æå–æµ‹è¯•èŠ‚ç‚¹"""
    
    def __init__(self):
        super().__init__('feature_extraction_tester')
        
        # åˆå§‹åŒ–CV Bridge
        self.bridge = CvBridge()
        
        # åˆ›å»ºæœåŠ¡å®¢æˆ·ç«¯
        self.client = self.create_client(FeatureExtraction, '/features/extract_features')
        
        # ç­‰å¾…æœåŠ¡å¯ç”¨
        while not self.client.wait_for_service(timeout_sec=1.0):
            self.get_logger().info('ç­‰å¾…ç‰¹å¾æå–æœåŠ¡...')
        
        self.get_logger().info('âœ… ç‰¹å¾æå–æœåŠ¡å·²è¿æ¥')

    def test_with_image_file(self, image_path, person_name="test_person"):
        """ä½¿ç”¨å›¾åƒæ–‡ä»¶æµ‹è¯•ç‰¹å¾æå–"""
        try:
            # è¯»å–å›¾åƒ
            if not os.path.exists(image_path):
                self.get_logger().error(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return False
                
            cv_image = cv2.imread(image_path)
            if cv_image is None:
                self.get_logger().error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                return False
                
            self.get_logger().info(f"ğŸ“¸ è¯»å–å›¾åƒæˆåŠŸ: {image_path}, å°ºå¯¸: {cv_image.shape}")
            
            # è½¬æ¢ä¸ºROSå›¾åƒæ¶ˆæ¯
            ros_image = self.bridge.cv2_to_imgmsg(cv_image, "bgr8")
            
            # åˆ›å»ºè¯·æ±‚
            request = FeatureExtraction.Request()
            request.image = ros_image
            request.person_name = person_name
            request.save_to_file = True
            request.output_path = ""  # ä½¿ç”¨é»˜è®¤è·¯å¾„
            
            # å‘é€è¯·æ±‚
            self.get_logger().info(f"ğŸš€ å‘é€ç‰¹å¾æå–è¯·æ±‚: {person_name}")
            future = self.client.call_async(request)
            
            # ç­‰å¾…å“åº”
            rclpy.spin_until_future_complete(self, future)
            
            if future.result() is not None:
                response = future.result()
                self.print_response(response)
                return response.success
            else:
                self.get_logger().error('âŒ æœåŠ¡è°ƒç”¨å¤±è´¥')
                return False
                
        except Exception as e:
            self.get_logger().error(f"æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_with_camera(self, camera_id=1, person_name="camera_person"):
        """ä½¿ç”¨æ‘„åƒå¤´æµ‹è¯•ç‰¹å¾æå–"""
        try:
            # æ‰“å¼€æ‘„åƒå¤´
            cap = cv2.VideoCapture(camera_id)
            if not cap.isOpened():
                self.get_logger().error(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ ID: {camera_id}")
                return False
                
            self.get_logger().info(f"ğŸ“¹ æ‘„åƒå¤´ {camera_id} å·²æ‰“å¼€")
            self.get_logger().info("æŒ‰ç©ºæ ¼é”®æ•è·å›¾åƒè¿›è¡Œç‰¹å¾æå–ï¼ŒæŒ‰'q'é€€å‡º")
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    self.get_logger().error("æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                    break
                    
                # å¦‚æœæ˜¯åŒç›®æ‘„åƒå¤´ï¼Œåªä½¿ç”¨å·¦åŠéƒ¨åˆ†
                if frame.shape[1] > frame.shape[0] * 1.5:  # å®½é«˜æ¯”å¤§äº1.5ï¼Œå¯èƒ½æ˜¯åŒç›®
                    mid_x = frame.shape[1] // 2
                    frame = frame[:, :mid_x]
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow('æ‘„åƒå¤´é¢„è§ˆ - æŒ‰ç©ºæ ¼é”®æå–ç‰¹å¾', frame)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord(' '):  # ç©ºæ ¼é”®
                    self.get_logger().info("ğŸ¯ æ•è·å›¾åƒï¼Œå¼€å§‹ç‰¹å¾æå–...")
                    
                    # è½¬æ¢ä¸ºROSå›¾åƒæ¶ˆæ¯
                    ros_image = self.bridge.cv2_to_imgmsg(frame, "bgr8")
                    
                    # åˆ›å»ºè¯·æ±‚
                    request = FeatureExtraction.Request()
                    request.image = ros_image
                    request.person_name = person_name
                    request.save_to_file = True
                    request.output_path = ""
                    
                    # å‘é€è¯·æ±‚
                    future = self.client.call_async(request)
                    
                    # ç­‰å¾…å“åº”
                    rclpy.spin_until_future_complete(self, future)
                    
                    if future.result() is not None:
                        response = future.result()
                        self.print_response(response)
                        if response.success:
                            self.get_logger().info("âœ… ç‰¹å¾æå–æˆåŠŸï¼ç»§ç»­é¢„è§ˆ...")
                        else:
                            self.get_logger().error("âŒ ç‰¹å¾æå–å¤±è´¥")
                    else:
                        self.get_logger().error('âŒ æœåŠ¡è°ƒç”¨å¤±è´¥')
            
            cap.release()
            cv2.destroyAllWindows()
            return True
            
        except Exception as e:
            self.get_logger().error(f"æ‘„åƒå¤´æµ‹è¯•å¤±è´¥: {e}")
            return False

    def print_response(self, response):
        """æ‰“å°å“åº”ç»“æœ"""
        self.get_logger().info("=" * 50)
        self.get_logger().info("ç‰¹å¾æå–ç»“æœ:")
        self.get_logger().info(f"æˆåŠŸ: {response.success}")
        self.get_logger().info(f"æ¶ˆæ¯: {response.message}")
        self.get_logger().info(f"æ£€æµ‹åˆ°çš„äººæ•°: {response.person_count}")
        
        if response.success and response.person_count > 0:
            self.get_logger().info(f"èº«ä½“æ¯”ä¾‹æ•°é‡: {len(response.body_ratios)}")
            if len(response.body_ratios) > 0:
                self.get_logger().info(f"èº«ä½“æ¯”ä¾‹æ ·ä¾‹: {response.body_ratios[:5]}...")
            
            self.get_logger().info(f"ä¸Šè£…é¢œè‰² (RGB): {response.shirt_color}")
            self.get_logger().info(f"ä¸‹è£…é¢œè‰² (RGB): {response.pants_color}")
            
            if response.result_image_path:
                self.get_logger().info(f"ç»“æœå›¾åƒ: {response.result_image_path}")
            
            if response.feature_data_path:
                self.get_logger().info(f"ç‰¹å¾æ•°æ®: {response.feature_data_path}")
        
        self.get_logger().info("=" * 50)


def main():
    """ä¸»å‡½æ•°"""
    rclpy.init()
    
    try:
        tester = FeatureExtractionTester()
        
        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
        if len(sys.argv) > 1:
            if sys.argv[1] == '--camera':
                # æ‘„åƒå¤´æµ‹è¯•
                camera_id = int(sys.argv[2]) if len(sys.argv) > 2 else 1
                person_name = sys.argv[3] if len(sys.argv) > 3 else "camera_test"
                tester.test_with_camera(camera_id, person_name)
            else:
                # å›¾åƒæ–‡ä»¶æµ‹è¯•
                image_path = sys.argv[1]
                person_name = sys.argv[2] if len(sys.argv) > 2 else "file_test"
                success = tester.test_with_image_file(image_path, person_name)
                if success:
                    tester.get_logger().info("ğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆ!")
                else:
                    tester.get_logger().error("ğŸ’¥ æµ‹è¯•å¤±è´¥!")
        else:
            tester.get_logger().info("ä½¿ç”¨æ–¹æ³•:")
            tester.get_logger().info("  å›¾åƒæ–‡ä»¶æµ‹è¯•: python3 test_feature_extraction.py <image_path> [person_name]")
            tester.get_logger().info("  æ‘„åƒå¤´æµ‹è¯•: python3 test_feature_extraction.py --camera [camera_id] [person_name]")
            
    except KeyboardInterrupt:
        pass
    finally:
        rclpy.shutdown()


if __name__ == '__main__':
    main() 